{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import decomposition\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ = pickle.load(open('train_data/train_data_new', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crew</th>\n",
       "      <th>experiment</th>\n",
       "      <th>seat</th>\n",
       "      <th>has_r_peak</th>\n",
       "      <th>has_ecg_peak</th>\n",
       "      <th>has_gsr_peak</th>\n",
       "      <th>event</th>\n",
       "      <th>time</th>\n",
       "      <th>eeg_fp1_filtered</th>\n",
       "      <th>eeg_f7_filtered</th>\n",
       "      <th>...</th>\n",
       "      <th>t5-p3-pz-p4-t6theta</th>\n",
       "      <th>t5-p3-pz-p4-t6alpha_low</th>\n",
       "      <th>t5-p3-pz-p4-t6alpha_high</th>\n",
       "      <th>t5-p3-pz-p4-t6beta</th>\n",
       "      <th>t5-p3-pz-p4-t6gamma</th>\n",
       "      <th>o1-o2theta</th>\n",
       "      <th>o1-o2alpha_low</th>\n",
       "      <th>o1-o2alpha_high</th>\n",
       "      <th>o1-o2beta</th>\n",
       "      <th>o1-o2gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.714367</td>\n",
       "      <td>-0.263545</td>\n",
       "      <td>0.926641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273852</td>\n",
       "      <td>-0.354617</td>\n",
       "      <td>-0.192741</td>\n",
       "      <td>-0.369647</td>\n",
       "      <td>-0.333646</td>\n",
       "      <td>0.528167</td>\n",
       "      <td>-1.048651</td>\n",
       "      <td>-0.590283</td>\n",
       "      <td>-0.240193</td>\n",
       "      <td>-0.020438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.714329</td>\n",
       "      <td>-0.177267</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270346</td>\n",
       "      <td>-0.306602</td>\n",
       "      <td>-0.149310</td>\n",
       "      <td>-0.375325</td>\n",
       "      <td>-0.327312</td>\n",
       "      <td>0.528217</td>\n",
       "      <td>-1.057778</td>\n",
       "      <td>-0.597163</td>\n",
       "      <td>-0.240114</td>\n",
       "      <td>-0.019782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.714292</td>\n",
       "      <td>0.201824</td>\n",
       "      <td>1.031278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261147</td>\n",
       "      <td>-0.212327</td>\n",
       "      <td>-0.062987</td>\n",
       "      <td>-0.382288</td>\n",
       "      <td>-0.315450</td>\n",
       "      <td>0.528216</td>\n",
       "      <td>-1.057227</td>\n",
       "      <td>-0.596747</td>\n",
       "      <td>-0.240121</td>\n",
       "      <td>-0.019822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.714254</td>\n",
       "      <td>0.214679</td>\n",
       "      <td>0.913735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260542</td>\n",
       "      <td>-0.206861</td>\n",
       "      <td>-0.057950</td>\n",
       "      <td>-0.382563</td>\n",
       "      <td>-0.314781</td>\n",
       "      <td>0.528218</td>\n",
       "      <td>-1.059037</td>\n",
       "      <td>-0.598115</td>\n",
       "      <td>-0.240097</td>\n",
       "      <td>-0.019691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.714217</td>\n",
       "      <td>0.128852</td>\n",
       "      <td>0.875913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269551</td>\n",
       "      <td>-0.297204</td>\n",
       "      <td>-0.140760</td>\n",
       "      <td>-0.376241</td>\n",
       "      <td>-0.326098</td>\n",
       "      <td>0.528136</td>\n",
       "      <td>-1.073101</td>\n",
       "      <td>-0.608798</td>\n",
       "      <td>-0.239813</td>\n",
       "      <td>-0.018671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  crew experiment seat has_r_peak has_ecg_peak has_gsr_peak event      time  \\\n",
       "0    1         CA    1          0            0            0     A -1.714367   \n",
       "1    1         CA    1          0            0            0     A -1.714329   \n",
       "2    1         CA    1          0            0            0     A -1.714292   \n",
       "3    1         CA    1          0            0            0     A -1.714254   \n",
       "4    1         CA    1          0            0            0     A -1.714217   \n",
       "\n",
       "   eeg_fp1_filtered  eeg_f7_filtered  ...  t5-p3-pz-p4-t6theta  \\\n",
       "0         -0.263545         0.926641  ...            -0.273852   \n",
       "1         -0.177267         1.004332  ...            -0.270346   \n",
       "2          0.201824         1.031278  ...            -0.261147   \n",
       "3          0.214679         0.913735  ...            -0.260542   \n",
       "4          0.128852         0.875913  ...            -0.269551   \n",
       "\n",
       "   t5-p3-pz-p4-t6alpha_low  t5-p3-pz-p4-t6alpha_high  t5-p3-pz-p4-t6beta  \\\n",
       "0                -0.354617                 -0.192741           -0.369647   \n",
       "1                -0.306602                 -0.149310           -0.375325   \n",
       "2                -0.212327                 -0.062987           -0.382288   \n",
       "3                -0.206861                 -0.057950           -0.382563   \n",
       "4                -0.297204                 -0.140760           -0.376241   \n",
       "\n",
       "   t5-p3-pz-p4-t6gamma  o1-o2theta  o1-o2alpha_low  o1-o2alpha_high  \\\n",
       "0            -0.333646    0.528167       -1.048651        -0.590283   \n",
       "1            -0.327312    0.528217       -1.057778        -0.597163   \n",
       "2            -0.315450    0.528216       -1.057227        -0.596747   \n",
       "3            -0.314781    0.528218       -1.059037        -0.598115   \n",
       "4            -0.326098    0.528136       -1.073101        -0.608798   \n",
       "\n",
       "   o1-o2beta  o1-o2gamma  \n",
       "0  -0.240193   -0.020438  \n",
       "1  -0.240114   -0.019782  \n",
       "2  -0.240121   -0.019822  \n",
       "3  -0.240097   -0.019691  \n",
       "4  -0.239813   -0.018671  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4867421, 196)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crew</th>\n",
       "      <th>experiment</th>\n",
       "      <th>seat</th>\n",
       "      <th>has_r_peak</th>\n",
       "      <th>has_ecg_peak</th>\n",
       "      <th>has_gsr_peak</th>\n",
       "      <th>event</th>\n",
       "      <th>time</th>\n",
       "      <th>eeg_fp1_filtered</th>\n",
       "      <th>eeg_f7_filtered</th>\n",
       "      <th>...</th>\n",
       "      <th>t5-p3-pz-p4-t6theta</th>\n",
       "      <th>t5-p3-pz-p4-t6alpha_low</th>\n",
       "      <th>t5-p3-pz-p4-t6alpha_high</th>\n",
       "      <th>t5-p3-pz-p4-t6beta</th>\n",
       "      <th>t5-p3-pz-p4-t6gamma</th>\n",
       "      <th>o1-o2theta</th>\n",
       "      <th>o1-o2alpha_low</th>\n",
       "      <th>o1-o2alpha_high</th>\n",
       "      <th>o1-o2beta</th>\n",
       "      <th>o1-o2gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.714367</td>\n",
       "      <td>-0.263545</td>\n",
       "      <td>0.926641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273852</td>\n",
       "      <td>-0.354617</td>\n",
       "      <td>-0.192741</td>\n",
       "      <td>-0.369647</td>\n",
       "      <td>-0.333646</td>\n",
       "      <td>0.528167</td>\n",
       "      <td>-1.048651</td>\n",
       "      <td>-0.590283</td>\n",
       "      <td>-0.240193</td>\n",
       "      <td>-0.020438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.714329</td>\n",
       "      <td>-0.177267</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270346</td>\n",
       "      <td>-0.306602</td>\n",
       "      <td>-0.149310</td>\n",
       "      <td>-0.375325</td>\n",
       "      <td>-0.327312</td>\n",
       "      <td>0.528217</td>\n",
       "      <td>-1.057778</td>\n",
       "      <td>-0.597163</td>\n",
       "      <td>-0.240114</td>\n",
       "      <td>-0.019782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.714292</td>\n",
       "      <td>0.201824</td>\n",
       "      <td>1.031278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261147</td>\n",
       "      <td>-0.212327</td>\n",
       "      <td>-0.062987</td>\n",
       "      <td>-0.382288</td>\n",
       "      <td>-0.315450</td>\n",
       "      <td>0.528216</td>\n",
       "      <td>-1.057227</td>\n",
       "      <td>-0.596747</td>\n",
       "      <td>-0.240121</td>\n",
       "      <td>-0.019822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.714254</td>\n",
       "      <td>0.214679</td>\n",
       "      <td>0.913735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260542</td>\n",
       "      <td>-0.206861</td>\n",
       "      <td>-0.057950</td>\n",
       "      <td>-0.382563</td>\n",
       "      <td>-0.314781</td>\n",
       "      <td>0.528218</td>\n",
       "      <td>-1.059037</td>\n",
       "      <td>-0.598115</td>\n",
       "      <td>-0.240097</td>\n",
       "      <td>-0.019691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.714217</td>\n",
       "      <td>0.128852</td>\n",
       "      <td>0.875913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269551</td>\n",
       "      <td>-0.297204</td>\n",
       "      <td>-0.140760</td>\n",
       "      <td>-0.376241</td>\n",
       "      <td>-0.326098</td>\n",
       "      <td>0.528136</td>\n",
       "      <td>-1.073101</td>\n",
       "      <td>-0.608798</td>\n",
       "      <td>-0.239813</td>\n",
       "      <td>-0.018671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  crew experiment seat has_r_peak has_ecg_peak has_gsr_peak event      time  \\\n",
       "0    1         CA    1          0            0            0     A -1.714367   \n",
       "1    1         CA    1          0            0            0     A -1.714329   \n",
       "2    1         CA    1          0            0            0     A -1.714292   \n",
       "3    1         CA    1          0            0            0     A -1.714254   \n",
       "4    1         CA    1          0            0            0     A -1.714217   \n",
       "\n",
       "   eeg_fp1_filtered  eeg_f7_filtered  ...  t5-p3-pz-p4-t6theta  \\\n",
       "0         -0.263545         0.926641  ...            -0.273852   \n",
       "1         -0.177267         1.004332  ...            -0.270346   \n",
       "2          0.201824         1.031278  ...            -0.261147   \n",
       "3          0.214679         0.913735  ...            -0.260542   \n",
       "4          0.128852         0.875913  ...            -0.269551   \n",
       "\n",
       "   t5-p3-pz-p4-t6alpha_low  t5-p3-pz-p4-t6alpha_high  t5-p3-pz-p4-t6beta  \\\n",
       "0                -0.354617                 -0.192741           -0.369647   \n",
       "1                -0.306602                 -0.149310           -0.375325   \n",
       "2                -0.212327                 -0.062987           -0.382288   \n",
       "3                -0.206861                 -0.057950           -0.382563   \n",
       "4                -0.297204                 -0.140760           -0.376241   \n",
       "\n",
       "   t5-p3-pz-p4-t6gamma  o1-o2theta  o1-o2alpha_low  o1-o2alpha_high  \\\n",
       "0            -0.333646    0.528167       -1.048651        -0.590283   \n",
       "1            -0.327312    0.528217       -1.057778        -0.597163   \n",
       "2            -0.315450    0.528216       -1.057227        -0.596747   \n",
       "3            -0.314781    0.528218       -1.059037        -0.598115   \n",
       "4            -0.326098    0.528136       -1.073101        -0.608798   \n",
       "\n",
       "   o1-o2beta  o1-o2gamma  \n",
       "0  -0.240193   -0.020438  \n",
       "1  -0.240114   -0.019782  \n",
       "2  -0.240121   -0.019822  \n",
       "3  -0.240097   -0.019691  \n",
       "4  -0.239813   -0.018671  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_Var(arr):\n",
    "    enc = []\n",
    "    for val in arr:\n",
    "        \n",
    "        if (val=='A'):\n",
    "            \n",
    "            enc.append(0)\n",
    "            \n",
    "        elif(val=='B'):\n",
    "            \n",
    "            enc.append(1)\n",
    "        elif(val=='C'):\n",
    "            \n",
    "            enc.append(2)\n",
    "        elif(val=='D'):\n",
    "            \n",
    "            enc.append(3)\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_vals = encode_Var(np.asarray(train_data_['event']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_['encoded_event'] = encoded_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing crew, experiment and event from trainable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data_['encoded_event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_.drop(['crew','event','experiment','encoded_event'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_['seat'] = train_data_['seat'].astype('int')\n",
    "train_data_['has_r_peak'] = train_data_['has_r_peak'].astype('int')\n",
    "train_data_['has_ecg_peak'] = train_data_['has_ecg_peak'].astype('int')\n",
    "train_data_['has_gsr_peak'] = train_data_['has_gsr_peak'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test_data_, open('test_data/test_data_newfeatures', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_ = pickle.load(open('test_data/test_data_newfeatures', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_cv, y_train, y_cv = train_test_split(train_data_, y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into train and cross validation using TimeSeriesSplit() in each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n",
    "\n",
    "exp = ['CA','DA','SS']\n",
    "tscv = TimeSeriesSplit(n_splits=2)\n",
    "\n",
    "features = list(train_data_.columns)\n",
    "x_train = pd.DataFrame(columns=features)\n",
    "x_cv = pd.DataFrame(columns=features)\n",
    "\n",
    "for e in exp:\n",
    "    \n",
    "    data_for_split = train_data_[(train_data_.experiment == e)].copy()\n",
    "    \n",
    "    for train_index, cv_index in tscv.split(data_for_split):\n",
    "        x_tr, x_te = data_for_split.iloc[train_index], data_for_split.iloc[cv_index]\n",
    "    \n",
    "    x_train = pd.concat([x_train,x_tr])\n",
    "    x_cv = pd.concat([x_cv,x_te])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Model Train logloss:  1.6453499132639418\n",
      "Random Model cv logloss:  1.6460736775749176\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for i in range(0,x_train.shape[0]):\n",
    "    ls_ = []\n",
    "    rand_probs = np.random.rand(1,4)\n",
    "    for prob in rand_probs[0]:\n",
    "        val = prob/sum(rand_probs[0])\n",
    "        ls_.append(val)\n",
    "    ls.append(ls_)\n",
    "\n",
    "rand_pred = np.asarray(ls)\n",
    "\n",
    "ls = []\n",
    "for i in range(0,x_cv.shape[0]):\n",
    "    ls_ = []\n",
    "    rand_probs = np.random.rand(1,4)\n",
    "    for prob in rand_probs[0]:\n",
    "        val = prob/sum(rand_probs[0])\n",
    "        ls_.append(val)\n",
    "    ls.append(ls_)\n",
    "\n",
    "rand_pred_cv = np.asarray(ls)\n",
    "\n",
    "print(\"Random Model Train logloss: \",log_loss(y_train,rand_pred))\n",
    "print(\"Random Model cv logloss: \",log_loss(y_cv,rand_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha:  0.001\n",
      "Train logloss:  0.2323471487581512\n",
      "CV logloss:  0.2323913465915608\n",
      "*********************************************\n",
      "For alpha:  0.01\n",
      "Train logloss:  0.2306172412503145\n",
      "CV logloss:  0.23071645530426088\n",
      "*********************************************\n",
      "For alpha:  0.1\n",
      "Train logloss:  0.2304177631267852\n",
      "CV logloss:  0.23051943067457187\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "C=[.001,.01,.1]\n",
    "for i in C:\n",
    "    clf = LogisticRegression(C=i)\n",
    "    clf.fit(x_train,y_train)\n",
    "    \n",
    "    pickle.dump(clf, open('LR_model_'+str(i), 'wb'))\n",
    "    \n",
    "    y_pred_train = clf.predict_proba(x_train)\n",
    "    y_pred_cv = clf.predict_proba(x_cv)\n",
    "    print(\"For alpha: \",i)\n",
    "    print(\"Train logloss: \",log_loss(y_train,y_pred_train))\n",
    "    print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))\n",
    "    print(\"*********************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha:  30\n",
      "Train logloss:  0.021732641224348193\n",
      "CV logloss:  0.05978690284047972\n",
      "*********************************************\n",
      "For alpha:  50\n",
      "Train logloss:  0.02113017660463825\n",
      "CV logloss:  0.05845845906898043\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "alpha=[30,50]\n",
    "for i in alpha:\n",
    "    rf_cfl=RandomForestClassifier(n_estimators=i,max_depth=50,n_jobs=-1)\n",
    "    rf_cfl.fit(x_train,y_train)\n",
    "    pickle.dump(rf_cfl, open('rf_model_'+str(i), 'wb'))\n",
    "    \n",
    "    y_pred_train = rf_cfl.predict_proba(x_train)\n",
    "    y_pred_cv = rf_cfl.predict_proba(x_cv)\n",
    "    print(\"For alpha: \",i)\n",
    "    print(\"Train logloss: \",log_loss(y_train,y_pred_train))\n",
    "    print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))\n",
    "    print(\"*********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "features = x_train.columns\n",
    "importances = rf_cfl.feature_importances_\n",
    "indices = (np.argsort(importances))[-15:]\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = []\n",
    "for i in indices:\n",
    "    important_features.append(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fp1-fp2theta', 'eeg_t3_filteredbeta', 't5-p3-pz-p4-t6theta', 'fp1-f3-c3-p3-o1gamma', 'eeg_t5_filteredgamma', 'eeg_fp2_filteredgamma', 'eeg_fz_filteredalpha_low', 't5-p3-pz-p4-t6gamma', 'eeg_f4_filteredtheta', 'fp2-f4-c4-p4-o2theta', 'eeg_o2_filteredtheta', 'eeg_poz_filteredgamma', 'eeg_f3_filteredtheta', 'fz-cz-pztheta', 'eeg_f8_filteredalpha_high', 'o1-o2theta', 'fp1-f3-c3-p3-o1beta', 'eeg_cz_filteredgamma', 'eeg_f7_filteredgamma', 't3-c3-cz-c4-t4gamma', 'gsr_moving_average', 'gsr_filtered', 'fp1-f3-c3-p3-o1theta', 'eeg_t4_filteredalpha_high', 'eeg_t4_filteredalpha_low', 'eeg_o1_filteredgamma', 'eeg_pz_filteredgamma', 'respiration rate', 'eeg_poz_filteredtheta', 'time']\n"
     ]
    }
   ],
   "source": [
    "print(important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So the crafted features like EEG frequency bands , respiration rate and gsr_moving_average are in top 30 features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWCpx536ckQO",
    "outputId": "bd03aa11-b598-4a44-bf9e-0dd291163939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logloss:  0.8417951182069895\n",
      "CV logloss:  0.926310529125779\n"
     ]
    }
   ],
   "source": [
    "alpha=[100]\n",
    "\n",
    "for i in alpha:\n",
    "    xgb_cfl=XGBClassifier(n_estimators=i,max_depth=5,colsample_bytree=0.7,nthread=-1)\n",
    "    xgb_cfl.fit(x_train,y_train)\n",
    "    \n",
    "    \n",
    "    xgb_calib_clf = CalibratedClassifierCV(xgb_cfl, method=\"sigmoid\")\n",
    "    xgb_calib_clf.fit(x_train, y_train)\n",
    "\n",
    "    pickle.dump(xgb_cfl, open('xgb_model_calib_'+str(i), 'wb'))\n",
    "\n",
    "    y_pred_train = xgb_calib_clf.predict_proba(x_train)\n",
    "    y_pred_cv = xgb_calib_clf.predict_proba(x_cv)\n",
    "    print(\"Train logloss: \",log_loss(y_train,y_pred_train))\n",
    "    print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 300\n",
    "xgb_cfl=XGBClassifier(n_estimators=alpha,max_depth=5,colsample_bytree=0.7,nthread=-1)\n",
    "xgb_cfl.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb_cfl, open('xgb_model_300', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logloss:  0.6493812944203944\n",
      "CV logloss:  0.8182311041460716\n"
     ]
    }
   ],
   "source": [
    "xgb_calib_clf = CalibratedClassifierCV(xgb_cfl, method=\"isotonic\")\n",
    "xgb_calib_clf.fit(x_train, y_train)  \n",
    "pickle.dump(xgb_cfl, open('xgb_model_calib_300', 'wb'))\n",
    "y_pred_train = xgb_calib_clf.predict_proba(x_train)\n",
    "y_pred_cv = xgb_calib_clf.predict_proba(x_cv)\n",
    "print(\"Train logloss: \",log_loss(y_train,y_pred_train))\n",
    "print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 478.2min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 644.1min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  50 | elapsed: 752.8min remaining: 752.8min\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  50 | elapsed: 875.7min remaining: 536.7min\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  50 | elapsed: 990.2min remaining: 347.9min\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  50 | elapsed: 1042.7min remaining: 169.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 1108.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_job...\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.5, 1],\n",
       "                                        'learning_rate': [0.01, 0.05, 0.15,\n",
       "                                                          0.2],\n",
       "                                        'max_depth': [3, 5, 7],\n",
       "                                        'n_estimators': [350, 450, 550],\n",
       "                                        'subsample': [0.3, 0.5, 1]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cfl=XGBClassifier()\n",
    "\n",
    "params={\n",
    "    'learning_rate':[0.01,0.05,0.15,0.2],\n",
    "     'n_estimators':[350,450,550],\n",
    "     'max_depth':[3,5,7],\n",
    "    'colsample_bytree':[0.3,0.5,1],\n",
    "    'subsample':[0.3,0.5,1]\n",
    "}\n",
    "rs_cfl=RandomizedSearchCV(xgb_cfl,param_distributions=params,verbose=10,n_jobs=-1,)\n",
    "rs_cfl.fit(x_train_feat_imp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rs_cfl, open('rs_cfl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1,\n",
       " 'n_estimators': 350,\n",
       " 'max_depth': 5,\n",
       " 'learning_rate': 0.01,\n",
       " 'colsample_bytree': 0.5}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_cfl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=350, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cfl_best=XGBClassifier(n_estimators=350,max_depth=5,learning_rate=0.01,colsample_bytree=0.5,subsample=1,nthread=-1)\n",
    "xgb_cfl_best.fit(x_train_feat_imp,y_train,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb_cfl_best, open('xgb_cfl_best', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logloss:  0.5932772290652153\n",
      "CV logloss:  0.8621281748998794\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = xgb_cfl_best.predict_proba(x_train_feat_imp)\n",
    "y_pred_cv = xgb_cfl_best.predict_proba(x_cv_feat_imp)\n",
    "print(\"Train logloss: \",log_loss(y_train,y_pred_train))\n",
    "print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 28.1min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  50 | elapsed: 29.2min remaining: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  50 | elapsed: 32.4min remaining: 19.8min\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  50 | elapsed: 41.0min remaining: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  50 | elapsed: 45.5min remaining:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 48.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LGBMClassifier(metric='multi_logloss', num_class=4,\n",
       "                                            objective='multiclass'),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.5, 0.7, 0.8],\n",
       "                                        'learning_rate': [0.01, 0.1, 0.3],\n",
       "                                        'max_depth': [3, 5, 7],\n",
       "                                        'n_estimators': [50, 100, 300],\n",
       "                                        'num_leaves': [20, 30, 50]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cfl = lgbm.LGBMClassifier(objective='multiclass',metric='multi_logloss',num_class=4)\n",
    "\n",
    "params={\n",
    "    'learning_rate':[0.01,0.1,0.3],\n",
    "     'n_estimators':[50,100,300],\n",
    "     'max_depth':[3,5,7],\n",
    "    'colsample_bytree':[0.5,0.7,0.8],\n",
    "    'num_leaves':[20,30,50]\n",
    "}\n",
    "rs_cfl=RandomizedSearchCV(lgbm_cfl,param_distributions=params,verbose=10,n_jobs=-1)\n",
    "rs_cfl.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 20,\n",
       " 'n_estimators': 300,\n",
       " 'max_depth': 5,\n",
       " 'learning_rate': 0.3,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_cfl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.7, max_depth=5, metric='multi_logloss',\n",
       "               n_estimators=500, num_class=4, num_leaves=30,\n",
       "               objective='multiclass')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cfl_2 = lgbm.LGBMClassifier(objective='multiclass',metric='multi_logloss',num_class=4,num_leaves=20,\n",
    "                                   n_estimators=500,max_depth=5,learning_rate=.3,colsample_bytree=0.7)\n",
    "\n",
    "lgbm_cfl_2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logloss:  0.08791106290181834\n",
      "CV logloss:  0.09007561061390987\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = lgbm_cfl_2.predict_proba(x_train)\n",
    "y_pred_cv = lgbm_cfl_2.predict_proba(x_cv)\n",
    "print(\"Train logloss: \",log_loss(y_train,y_pred_train))\n",
    "print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping only important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_feat_imp = x_train.loc[:, important_features]\n",
    "\n",
    "x_cv_feat_imp = x_cv.loc[:, important_features]\n",
    "\n",
    "x_test_feat_imp = test_data_.loc[:, important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.7, learning_rate=0.01, max_depth=5,\n",
       "               metric='multi_logloss', n_estimators=2000, num_class=4,\n",
       "               num_leaves=30, objective='multiclass')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cfl_fs = lgbm.LGBMClassifier(objective='multiclass',metric='multi_logloss',num_class=4,num_leaves=30,\n",
    "                                   n_estimators=2000,max_depth=5,learning_rate=.01,colsample_bytree=0.7)\n",
    "\n",
    "lgbm_cfl_fs.fit(x_tr_feat_imp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logloss:  0.18455567751191237\n",
      "CV logloss:  0.18614070117535605\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = lgbm_cfl_fs.predict_proba(x_tr_feat_imp)\n",
    "y_pred_cv = lgbm_cfl_fs.predict_proba(x_cv_feat_imp)\n",
    "print(\"Train logloss: \",log_loss(y_train,y_pred_train))\n",
    "print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.7, learning_rate=0.01, max_depth=3,\n",
       "               metric='multi_logloss', n_estimators=4000, num_class=4,\n",
       "               num_leaves=30, objective='multiclass', reg_alpha=0.1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cfl_ = lgbm.LGBMClassifier(objective='multiclass',metric='multi_logloss',num_class=4,num_leaves=30,\n",
    "                                   n_estimators=4000,max_depth=3,learning_rate=.01,colsample_bytree=0.7,reg_alpha=.1)\n",
    "\n",
    "lgbm_cfl_.fit(tr_feat_imp, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logloss:  0.26275757589186405\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm_cfl_.predict_proba(x_tr_feat_imp)\n",
    "y_pred_cv = lgbm_cfl_.predict_proba(x_cv_feat_imp)\n",
    "print(\"Train logloss: \",log_loss(y_test,y_pred))\n",
    "print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components = 100\n",
    "pca_ = pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dt_pca = pca_.transform(x_train)\n",
    "cv_dt_pca = pca_.transform(x_cv)\n",
    "te_dt_pca = pca_.transform(test_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_var_explained1 = pca.explained_variance_ / np.sum(pca.explained_variance_)\n",
    "\n",
    "cum_var_explained1 = np.cumsum(percentage_var_explained1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(6, 4))\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(cum_var_explained1, linewidth=2)\n",
    "plt.axis('tight')\n",
    "plt.grid()\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('Cumulative_explained_variance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above graph indicates that 100% variance can be achieved with around 70 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components = 70\n",
    "pca_ = pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dt_pca = pca_.transform(x_train)\n",
    "cv_dt_pca = pca_.transform(x_cv)\n",
    "te_dt_pca = pca_.transform(test_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.8, max_depth=7, metric='multi_logloss',\n",
       "               min_data_in_leaf=100, n_estimators=10, num_class=4,\n",
       "               num_leaves=40, objective='multiclass', reg_alpha=0.01)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cfl_ = lgbm.LGBMClassifier(objective='multiclass',metric='multi_logloss',num_class=4,num_leaves=40,\n",
    "                                   n_estimators=10,max_depth=7,learning_rate=.1,colsample_bytree=0.8,min_data_in_leaf=100,reg_alpha=.01)\n",
    "\n",
    "lgbm_cfl_.fit(tr_data_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logloss:  0.5678693360983159\n",
      "CV logloss:  0.5681861959205138\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm_cfl_.predict_proba(tr_data_pca)\n",
    "y_pred_cv = lgbm_cfl_.predict_proba(cv_data_pca)\n",
    "print(\"Train logloss: \",log_loss(y_train,y_pred))\n",
    "print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  50 | elapsed:  5.1min remaining:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  50 | elapsed:  6.2min remaining:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  50 | elapsed:  7.8min remaining:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  50 | elapsed:  7.8min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LGBMClassifier(metric='multi_logloss', num_class=4,\n",
       "                                            objective='multiclass'),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.5, 0.7, 0.8],\n",
       "                                        'learning_rate': [0.01, 0.1, 0.3],\n",
       "                                        'max_depth': [3, 5, 7],\n",
       "                                        'min_data_in_leaf': [50, 100, 400],\n",
       "                                        'n_estimators': [25, 50, 100],\n",
       "                                        'num_leaves': [30, 40, 60],\n",
       "                                        'reg_alpha': [0.01, 0.1]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cfl = lgbm.LGBMClassifier(objective='multiclass',metric='multi_logloss',num_class=4)\n",
    "\n",
    "params={\n",
    "    'learning_rate':[0.01,0.1,0.3],\n",
    "     'n_estimators':[25,50,100],\n",
    "     'max_depth':[3,5,7],\n",
    "    'colsample_bytree':[0.5,0.7,0.8],\n",
    "    'num_leaves':[30,40,60],\n",
    "    'min_data_in_leaf':[50,100,400],\n",
    "    'reg_alpha':[.01,.1]\n",
    "}\n",
    "rs_cfl=RandomizedSearchCV(lgbm_cfl,param_distributions=params,verbose=10,n_jobs=-1)\n",
    "rs_cfl.fit(tr_data_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_alpha': 0.01,\n",
       " 'num_leaves': 30,\n",
       " 'n_estimators': 100,\n",
       " 'min_data_in_leaf': 50,\n",
       " 'max_depth': 7,\n",
       " 'learning_rate': 0.3,\n",
       " 'colsample_bytree': 0.5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_cfl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.5, learning_rate=0.3, max_depth=7,\n",
       "               metric='multi_logloss', min_data_in_leaf=50, num_class=4,\n",
       "               num_leaves=30, objective='multiclass', reg_alpha=0.01)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cfl_ = lgbm.LGBMClassifier(objective='multiclass',metric='multi_logloss',num_class=4,num_leaves=30,\n",
    "                                   n_estimators=100,max_depth=7,learning_rate=.3,colsample_bytree=0.5,min_data_in_leaf=50,reg_alpha=.01)\n",
    "\n",
    "lgbm_cfl_.fit(tr_data_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logloss:  0.23142617288868655\n",
      "CV logloss:  0.23542096312896782\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm_cfl_.predict_proba(tr_data_pca)\n",
    "y_pred_cv = lgbm_cfl_.predict_proba(cv_data_pca)\n",
    "print(\"Train logloss: \",log_loss(y_train,y_pred))\n",
    "print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train, d_test, y_dtrain, y_dtest = train_test_split(train_data_, y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_train, d2_train, y_d1train, y_d2train = train_test_split(d_train, y_dtrain, test_size=0.50, stratify=y_dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSample(data,target):\n",
    "    \n",
    "    dt_size = int(.7*data.shape[0])\n",
    "    \n",
    "    rand_index = np.random.choice(data.shape[0],dt_size,replace=True)\n",
    "    \n",
    "    sampled_data = data[data.index.isin(rand_index)]\n",
    "    \n",
    "    sampled_y = target[target.index.isin(rand_index)]\n",
    "    \n",
    "    return sampled_data, sampled_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBaseModel(modelName,data,target):\n",
    "    \n",
    "    \n",
    "    if(modelName=='Decision Tree'):\n",
    "        \n",
    "        model = DecisionTreeClassifier()\n",
    "        \n",
    "    elif(modelName=='KNN'):\n",
    "        \n",
    "        model = KNeighborsClassifier(algorithm='kd_tree')\n",
    "    \n",
    "    elif(modelName=='Logistic Regression'):\n",
    "        \n",
    "        model = LogisticRegression()\n",
    "    \n",
    "    elif(modelName=='SVM'):\n",
    "        \n",
    "        model = SVC()\n",
    "        \n",
    "    elif(modelName=='Naive Bayes'):\n",
    "        \n",
    "        model = GaussianNB()\n",
    "        \n",
    "    elif(modelName=='LGBM'):\n",
    "        \n",
    "        model = lgbm.LGBMClassifier(objective='multiclass',metric='multi_logloss',num_class=4,num_leaves=40,\n",
    "                                   n_estimators=30,max_depth=7,learning_rate=.1,colsample_bytree=0.5)\n",
    "    elif(modelName=='Random Forest'):\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=20,n_jobs=-1)\n",
    "        \n",
    "    elif(modelName=='XGB'):\n",
    "        \n",
    "        model = XGBClassifier(n_estimators=40,max_depth=5,learning_rate=0.01,colsample_bytree=0.5,subsample=1,nthread=-1)\n",
    "        \n",
    "            \n",
    "    model.fit(data,target)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPredictionsDataset(models_list,D1,Y1,D2):\n",
    "    \n",
    "    trained_models = []\n",
    "    \n",
    "    for i,m in tqdm(enumerate(models_list)):\n",
    "\n",
    "        dt_sample, y_sample = createSample(D1,Y1)\n",
    "        \n",
    "        trained_model = createBaseModel(m,dt_sample,y_sample)\n",
    "        \n",
    "        trained_models.append(trained_model)\n",
    "        \n",
    "        print(\"Trained model: \",m)\n",
    "\n",
    "        if(i==0):\n",
    "\n",
    "            predicts_base = trained_model.predict(D2)\n",
    "            predicts_base = pd.DataFrame(predicts_base)\n",
    "\n",
    "        else:\n",
    "\n",
    "            pred = trained_model.predict(D2)\n",
    "            pred = pd.DataFrame(pred)\n",
    "\n",
    "        if(i>0):\n",
    "\n",
    "            predicts_base = pd.concat([predicts_base,pred],axis=1)\n",
    "            \n",
    "    return predicts_base,trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model:  Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:26, 26.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model:  Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:57, 27.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model:  LGBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:17, 25.67s/it]\n"
     ]
    }
   ],
   "source": [
    "models = ['Logistic Regression','Naive Bayes','LGBM']\n",
    "\n",
    "pred_data_base, base_models = createPredictionsDataset(models,d1_train,y_d1train,d2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now training metaclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_classifier = DecisionTreeClassifier()\n",
    "\n",
    "meta_classifier.fit(pred_data_base,y_d2train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,tr_m in enumerate(base_models):\n",
    "    \n",
    "    if(i==0):\n",
    "    \n",
    "        predicts_base_test = tr_m.predict(d_test)\n",
    "    \n",
    "        predicts_base_test = pd.DataFrame(predicts_base_test)\n",
    "\n",
    "    if(i>0):\n",
    "        \n",
    "        preds = tr_m.predict(d_test)\n",
    "        preds = pd.DataFrame(preds)\n",
    "\n",
    "        predicts_base_test = pd.concat([predicts_base_test,preds],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test logloss:  0.4860050431323418\n"
     ]
    }
   ],
   "source": [
    "final_test_preds = meta_classifier.predict_proba(predicts_base_test)\n",
    "\n",
    "print(\"Test logloss: \",log_loss(y_dtest,final_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(meta_classifier, open('stacked_classifier/meta_classifier', 'wb'))\n",
    "pickle.dump(d_test_, open('stacked_classifier/d_test_', 'wb'))\n",
    "pickle.dump(base_models, open('stacked_classifier/base_models', 'wb'))\n",
    "pickle.dump(pca_, open('stacked_classifier/pca_', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,tr_m in enumerate(base_models):\n",
    "    \n",
    "    if(i==0):\n",
    "    \n",
    "        submission_pred_data = tr_m.predict(test_data_)\n",
    "    \n",
    "        submission_pred_data = pd.DataFrame(submission_pred_data)\n",
    "\n",
    "    if(i>0):\n",
    "        \n",
    "        submission_preds_dt = tr_m.predict(test_data_)\n",
    "        submission_preds_dt = pd.DataFrame(submission_preds_dt)\n",
    "\n",
    "        submission_pred_data = pd.concat([submission_pred_data,submission_preds_dt],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(submission_pred_data, open('stacked_classifier/submission_pred_data2', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_preds = meta_classifier.predict_proba(submission_pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cv = pd.DataFrame(data = submission_preds,columns = ['A','B','C','D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cv['id'] = submission_cv.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cv = submission_cv[['id','A','B','C','D']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.944718</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.001769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.420829</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>0.555222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.420829</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>0.555222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.420829</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>0.555222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.420829</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>0.555222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         A         B         C         D\n",
       "0   0  0.944718  0.003441  0.050072  0.001769\n",
       "1   1  0.420829  0.023949  0.555222  0.000000\n",
       "2   2  0.420829  0.023949  0.555222  0.000000\n",
       "3   3  0.420829  0.023949  0.555222  0.000000\n",
       "4   4  0.420829  0.023949  0.555222  0.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17965143, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cv.to_csv('Custom_stacking_classifier10.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with new added features like heart rate , respiration rate and eeg power features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.5, max_depth=7, metric='multi_logloss',\n",
       "               min_data_in_leaf=100, n_estimators=40, num_class=4,\n",
       "               num_leaves=30, objective='multiclass', reg_alpha=0.01)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cfl_ = lgbm.LGBMClassifier(objective='multiclass',metric='multi_logloss',num_class=4,num_leaves=30,\n",
    "                                   n_estimators=40,max_depth=7,learning_rate=.1,colsample_bytree=0.5,min_data_in_leaf=100,reg_alpha=.01)\n",
    "\n",
    "lgbm_cfl_.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logloss:  0.0878268086048108\n",
      "CV logloss:  0.08801411151276309\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm_cfl_.predict_proba(x_train)\n",
    "y_pred_cv = lgbm_cfl_.predict_proba(x_cv)\n",
    "print(\"Train logloss: \",log_loss(y_train,y_pred))\n",
    "print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.5, max_depth=7, metric='multi_logloss',\n",
       "               min_data_in_leaf=100, n_estimators=40, num_class=4,\n",
       "               num_leaves=30, objective='multiclass', reg_alpha=0.01)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cfl_ = lgbm.LGBMClassifier(objective='multiclass',metric='multi_logloss',num_class=4,num_leaves=40,\n",
    "                                   n_estimators=30,max_depth=7,learning_rate=.1,colsample_bytree=0.5,min_data_in_leaf=100,reg_alpha=.01)\n",
    "\n",
    "lgbm_cfl_.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logloss:  0.08963250942404453\n",
      "CV logloss:  0.09029178600959277\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm_cfl_.predict_proba(x_train)\n",
    "y_pred_cv = lgbm_cfl_.predict_proba(x_cv)\n",
    "print(\"Train logloss: \",log_loss(y_train,y_pred))\n",
    "print(\"CV logloss: \",log_loss(y_cv,y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lgbm_cfl_, open('best_model/lgbm_40est', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Input,Activation,Dropout,Flatten,Conv1D,BatchNormalization,MaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@Rehan_Sayyad/how-to-use-convolutional-neural-networks-for-time-series-classification-80575131a474\n",
    "\n",
    "train_dt = x_train.to_numpy()\n",
    "cv_dt = x_cv.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_cv = y_cv.to_numpy()\n",
    "\n",
    "train_dt = tr_data_pca.reshape(train_dt.shape[0],train_dt.shape[1], 1)\n",
    "cv_dt = cv_data_pca.reshape(cv_dt.shape[0],cv_dt.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dt = test_data_.to_numpy()\n",
    "test_dt = te_data_pca.reshape(test_data_.shape[0],test_data_.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = tf.keras.utils.to_categorical(y_train, 4)\n",
    "y_cv_ = tf.keras.utils.to_categorical(y_cv, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model =keras.models.Sequential()\n",
    "\n",
    "model.add(Input(shape=(train_dt.shape[1],1)))\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=8, padding='valid', activation='relu', kernel_initializer=tf.keras.initializers.he_normal()))\n",
    "model.add(Conv1D(filters=64, kernel_size=6, padding='valid', activation='relu', kernel_initializer=tf.keras.initializers.he_normal()))\n",
    "model.add(MaxPool1D(pool_size=2, padding='valid'))\n",
    "\n",
    "model.add(Dropout(.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=30,activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=10)))\n",
    "\n",
    "model.add(Dense(units=20,activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=10)))\n",
    "\n",
    "model.add(Dense(units=4,activation='softmax',kernel_initializer=tf.keras.initializers.he_normal(seed=3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 8, 128)            1152      \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 3, 64)             49216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 30)                1950      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 53,022\n",
      "Trainable params: 53,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"model_save/weights-{epoch:02d}-{accuracy:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "73/74 [============================>.] - ETA: 0s - loss: 1.1248 - accuracy: 0.6031\n",
      "Epoch 00001: val_loss improved from inf to 0.84586, saving model to model_save/weights-01-0.6031.hdf5\n",
      "74/74 [==============================] - 32s 433ms/step - loss: 1.1248 - accuracy: 0.6031 - val_loss: 0.8459 - val_accuracy: 0.6682\n",
      "Epoch 2/5\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.8208 - accuracy: 0.6721\n",
      "Epoch 00002: val_loss improved from 0.84586 to 0.75507, saving model to model_save/weights-02-0.6721.hdf5\n",
      "74/74 [==============================] - 32s 439ms/step - loss: 0.8208 - accuracy: 0.6721 - val_loss: 0.7551 - val_accuracy: 0.6981\n",
      "Epoch 3/5\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7379 - accuracy: 0.7118\n",
      "Epoch 00003: val_loss improved from 0.75507 to 0.69758, saving model to model_save/weights-03-0.7118.hdf5\n",
      "74/74 [==============================] - 32s 438ms/step - loss: 0.7379 - accuracy: 0.7118 - val_loss: 0.6976 - val_accuracy: 0.7255\n",
      "Epoch 4/5\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6788 - accuracy: 0.7410\n",
      "Epoch 00004: val_loss improved from 0.69758 to 0.64807, saving model to model_save/weights-04-0.7410.hdf5\n",
      "74/74 [==============================] - 33s 448ms/step - loss: 0.6788 - accuracy: 0.7410 - val_loss: 0.6481 - val_accuracy: 0.7527\n",
      "Epoch 5/5\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6401 - accuracy: 0.7608\n",
      "Epoch 00005: val_loss improved from 0.64807 to 0.59322, saving model to model_save/weights-05-0.7608.hdf5\n",
      "74/74 [==============================] - 33s 451ms/step - loss: 0.6401 - accuracy: 0.7608 - val_loss: 0.5932 - val_accuracy: 0.7864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc5faaef2e0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch=50000\n",
    "ep = 5\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "#optimizer = tf.keras.optimizers.Adadelta(learning_rate=0.01)\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=.01, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "model.fit(train_dt,y_train_,validation_data=(cv_dt,y_cv_),epochs=ep,batch_size=batch,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6230 - accuracy: 0.7682\n",
      "Epoch 00001: val_loss did not improve from 0.59322\n",
      "74/74 [==============================] - 33s 452ms/step - loss: 0.6230 - accuracy: 0.7682 - val_loss: 0.5999 - val_accuracy: 0.7762\n",
      "Epoch 2/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5836 - accuracy: 0.7900\n",
      "Epoch 00002: val_loss improved from 0.59322 to 0.58028, saving model to model_save/weights-02-0.7900.hdf5\n",
      "74/74 [==============================] - 33s 448ms/step - loss: 0.5836 - accuracy: 0.7900 - val_loss: 0.5803 - val_accuracy: 0.7892\n",
      "Epoch 3/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5692 - accuracy: 0.7968\n",
      "Epoch 00003: val_loss did not improve from 0.58028\n",
      "74/74 [==============================] - 33s 444ms/step - loss: 0.5692 - accuracy: 0.7968 - val_loss: 0.5835 - val_accuracy: 0.7852\n",
      "Epoch 4/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5539 - accuracy: 0.8039\n",
      "Epoch 00004: val_loss improved from 0.58028 to 0.52174, saving model to model_save/weights-04-0.8039.hdf5\n",
      "74/74 [==============================] - 35s 477ms/step - loss: 0.5539 - accuracy: 0.8039 - val_loss: 0.5217 - val_accuracy: 0.8185\n",
      "Epoch 5/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5383 - accuracy: 0.8108\n",
      "Epoch 00005: val_loss did not improve from 0.52174\n",
      "74/74 [==============================] - 33s 446ms/step - loss: 0.5383 - accuracy: 0.8108 - val_loss: 0.5289 - val_accuracy: 0.8116\n",
      "Epoch 6/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5249 - accuracy: 0.8165\n",
      "Epoch 00006: val_loss improved from 0.52174 to 0.49597, saving model to model_save/weights-06-0.8165.hdf5\n",
      "74/74 [==============================] - 34s 459ms/step - loss: 0.5248 - accuracy: 0.8165 - val_loss: 0.4960 - val_accuracy: 0.8247\n",
      "Epoch 7/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5199 - accuracy: 0.8183\n",
      "Epoch 00007: val_loss did not improve from 0.49597\n",
      "74/74 [==============================] - 34s 460ms/step - loss: 0.5199 - accuracy: 0.8183 - val_loss: 0.5167 - val_accuracy: 0.8158\n",
      "Epoch 8/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5283 - accuracy: 0.8152\n",
      "Epoch 00008: val_loss did not improve from 0.49597\n",
      "74/74 [==============================] - 35s 476ms/step - loss: 0.5283 - accuracy: 0.8152 - val_loss: 0.5206 - val_accuracy: 0.8110\n",
      "Epoch 9/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5078 - accuracy: 0.8239\n",
      "Epoch 00009: val_loss did not improve from 0.49597\n",
      "74/74 [==============================] - 34s 465ms/step - loss: 0.5078 - accuracy: 0.8239 - val_loss: 0.4965 - val_accuracy: 0.8255\n",
      "Epoch 10/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5181 - accuracy: 0.8185\n",
      "Epoch 00010: val_loss improved from 0.49597 to 0.48393, saving model to model_save/weights-10-0.8185.hdf5\n",
      "74/74 [==============================] - 34s 460ms/step - loss: 0.5181 - accuracy: 0.8185 - val_loss: 0.4839 - val_accuracy: 0.8334\n",
      "Epoch 11/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4936 - accuracy: 0.8290\n",
      "Epoch 00011: val_loss improved from 0.48393 to 0.46038, saving model to model_save/weights-11-0.8290.hdf5\n",
      "74/74 [==============================] - 34s 454ms/step - loss: 0.4936 - accuracy: 0.8290 - val_loss: 0.4604 - val_accuracy: 0.8420\n",
      "Epoch 12/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4958 - accuracy: 0.8279\n",
      "Epoch 00012: val_loss did not improve from 0.46038\n",
      "74/74 [==============================] - 33s 450ms/step - loss: 0.4957 - accuracy: 0.8279 - val_loss: 0.4851 - val_accuracy: 0.8347\n",
      "Epoch 13/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4809 - accuracy: 0.8336\n",
      "Epoch 00013: val_loss did not improve from 0.46038\n",
      "74/74 [==============================] - 34s 455ms/step - loss: 0.4809 - accuracy: 0.8336 - val_loss: 0.5261 - val_accuracy: 0.8163\n",
      "Epoch 14/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5540 - accuracy: 0.8035\n",
      "Epoch 00014: val_loss did not improve from 0.46038\n",
      "74/74 [==============================] - 34s 464ms/step - loss: 0.5540 - accuracy: 0.8035 - val_loss: 0.5173 - val_accuracy: 0.8158\n",
      "Epoch 15/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5035 - accuracy: 0.8261\n",
      "Epoch 00015: val_loss did not improve from 0.46038\n",
      "74/74 [==============================] - 35s 471ms/step - loss: 0.5035 - accuracy: 0.8261 - val_loss: 0.5001 - val_accuracy: 0.8249\n",
      "Epoch 16/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4923 - accuracy: 0.8311\n",
      "Epoch 00016: val_loss did not improve from 0.46038\n",
      "74/74 [==============================] - 33s 447ms/step - loss: 0.4923 - accuracy: 0.8311 - val_loss: 0.5538 - val_accuracy: 0.8063\n",
      "Epoch 17/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4910 - accuracy: 0.8315\n",
      "Epoch 00017: val_loss did not improve from 0.46038\n",
      "74/74 [==============================] - 34s 464ms/step - loss: 0.4910 - accuracy: 0.8315 - val_loss: 0.4880 - val_accuracy: 0.8304\n",
      "Epoch 18/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4815 - accuracy: 0.8355\n",
      "Epoch 00018: val_loss improved from 0.46038 to 0.45806, saving model to model_save/weights-18-0.8355.hdf5\n",
      "74/74 [==============================] - 34s 462ms/step - loss: 0.4815 - accuracy: 0.8355 - val_loss: 0.4581 - val_accuracy: 0.8455\n",
      "Epoch 19/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.8364\n",
      "Epoch 00019: val_loss improved from 0.45806 to 0.44706, saving model to model_save/weights-19-0.8364.hdf5\n",
      "74/74 [==============================] - 35s 467ms/step - loss: 0.4792 - accuracy: 0.8364 - val_loss: 0.4471 - val_accuracy: 0.8467\n",
      "Epoch 20/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4821 - accuracy: 0.8350\n",
      "Epoch 00020: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 34s 455ms/step - loss: 0.4821 - accuracy: 0.8350 - val_loss: 0.4574 - val_accuracy: 0.8417\n",
      "Epoch 21/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.8414\n",
      "Epoch 00021: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 35s 469ms/step - loss: 0.4659 - accuracy: 0.8414 - val_loss: 0.4870 - val_accuracy: 0.8330\n",
      "Epoch 22/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4733 - accuracy: 0.8382\n",
      "Epoch 00022: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 34s 461ms/step - loss: 0.4733 - accuracy: 0.8382 - val_loss: 0.4716 - val_accuracy: 0.8360\n",
      "Epoch 23/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4591 - accuracy: 0.8436\n",
      "Epoch 00023: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 39s 523ms/step - loss: 0.4591 - accuracy: 0.8436 - val_loss: 0.4568 - val_accuracy: 0.8417\n",
      "Epoch 24/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4782 - accuracy: 0.8354\n",
      "Epoch 00024: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 34s 465ms/step - loss: 0.4782 - accuracy: 0.8354 - val_loss: 0.4947 - val_accuracy: 0.8316\n",
      "Epoch 25/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4696 - accuracy: 0.8391\n",
      "Epoch 00025: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 35s 475ms/step - loss: 0.4696 - accuracy: 0.8391 - val_loss: 0.5296 - val_accuracy: 0.8139\n",
      "Epoch 26/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4914 - accuracy: 0.8320\n",
      "Epoch 00026: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 35s 480ms/step - loss: 0.4914 - accuracy: 0.8320 - val_loss: 0.4715 - val_accuracy: 0.8390\n",
      "Epoch 27/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4571 - accuracy: 0.8437\n",
      "Epoch 00027: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 34s 463ms/step - loss: 0.4571 - accuracy: 0.8437 - val_loss: 0.5549 - val_accuracy: 0.8067\n",
      "Epoch 28/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4525 - accuracy: 0.8456\n",
      "Epoch 00028: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 35s 473ms/step - loss: 0.4525 - accuracy: 0.8456 - val_loss: 0.5455 - val_accuracy: 0.8087\n",
      "Epoch 29/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4557 - accuracy: 0.8440\n",
      "Epoch 00029: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 35s 479ms/step - loss: 0.4557 - accuracy: 0.8440 - val_loss: 0.4632 - val_accuracy: 0.8408\n",
      "Epoch 30/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4416 - accuracy: 0.8496\n",
      "Epoch 00030: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 35s 471ms/step - loss: 0.4416 - accuracy: 0.8496 - val_loss: 0.5541 - val_accuracy: 0.8064\n",
      "Epoch 31/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4417 - accuracy: 0.8495\n",
      "Epoch 00031: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 36s 490ms/step - loss: 0.4417 - accuracy: 0.8495 - val_loss: 0.4796 - val_accuracy: 0.8315\n",
      "Epoch 32/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4466 - accuracy: 0.8474\n",
      "Epoch 00032: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 34s 465ms/step - loss: 0.4466 - accuracy: 0.8474 - val_loss: 0.4754 - val_accuracy: 0.8342\n",
      "Epoch 33/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4349 - accuracy: 0.8515\n",
      "Epoch 00033: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 34s 463ms/step - loss: 0.4349 - accuracy: 0.8515 - val_loss: 0.5186 - val_accuracy: 0.8241\n",
      "Epoch 34/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4317 - accuracy: 0.8527\n",
      "Epoch 00034: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 37s 497ms/step - loss: 0.4317 - accuracy: 0.8527 - val_loss: 0.5482 - val_accuracy: 0.8208\n",
      "Epoch 35/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4311 - accuracy: 0.8530\n",
      "Epoch 00035: val_loss did not improve from 0.44706\n",
      "74/74 [==============================] - 35s 472ms/step - loss: 0.4311 - accuracy: 0.8530 - val_loss: 0.5504 - val_accuracy: 0.8108\n",
      "Epoch 36/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.8500\n",
      "Epoch 00036: val_loss improved from 0.44706 to 0.42167, saving model to model_save/weights-36-0.8500.hdf5\n",
      "74/74 [==============================] - 35s 475ms/step - loss: 0.4375 - accuracy: 0.8500 - val_loss: 0.4217 - val_accuracy: 0.8554\n",
      "Epoch 37/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4212 - accuracy: 0.8563\n",
      "Epoch 00037: val_loss did not improve from 0.42167\n",
      "74/74 [==============================] - 36s 491ms/step - loss: 0.4212 - accuracy: 0.8563 - val_loss: 0.5151 - val_accuracy: 0.8298\n",
      "Epoch 38/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4244 - accuracy: 0.8551\n",
      "Epoch 00038: val_loss did not improve from 0.42167\n",
      "74/74 [==============================] - 36s 487ms/step - loss: 0.4244 - accuracy: 0.8551 - val_loss: 0.4690 - val_accuracy: 0.8438\n",
      "Epoch 39/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4180 - accuracy: 0.8573\n",
      "Epoch 00039: val_loss did not improve from 0.42167\n",
      "74/74 [==============================] - 35s 477ms/step - loss: 0.4180 - accuracy: 0.8573 - val_loss: 0.4697 - val_accuracy: 0.8425\n",
      "Epoch 40/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4217 - accuracy: 0.8557\n",
      "Epoch 00040: val_loss improved from 0.42167 to 0.41785, saving model to model_save/weights-40-0.8557.hdf5\n",
      "74/74 [==============================] - 36s 485ms/step - loss: 0.4217 - accuracy: 0.8557 - val_loss: 0.4178 - val_accuracy: 0.8570\n",
      "Epoch 41/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4166 - accuracy: 0.8576\n",
      "Epoch 00041: val_loss did not improve from 0.41785\n",
      "74/74 [==============================] - 35s 478ms/step - loss: 0.4166 - accuracy: 0.8576 - val_loss: 0.4628 - val_accuracy: 0.8440\n",
      "Epoch 42/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4374 - accuracy: 0.8500\n",
      "Epoch 00042: val_loss did not improve from 0.41785\n",
      "74/74 [==============================] - 36s 481ms/step - loss: 0.4374 - accuracy: 0.8500 - val_loss: 0.5124 - val_accuracy: 0.8269\n",
      "Epoch 43/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4177 - accuracy: 0.8573\n",
      "Epoch 00043: val_loss did not improve from 0.41785\n",
      "74/74 [==============================] - 34s 465ms/step - loss: 0.4177 - accuracy: 0.8573 - val_loss: 0.4678 - val_accuracy: 0.8443\n",
      "Epoch 44/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4104 - accuracy: 0.8596\n",
      "Epoch 00044: val_loss did not improve from 0.41785\n",
      "74/74 [==============================] - 35s 480ms/step - loss: 0.4103 - accuracy: 0.8596 - val_loss: 0.4403 - val_accuracy: 0.8495\n",
      "Epoch 45/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4069 - accuracy: 0.8607\n",
      "Epoch 00045: val_loss did not improve from 0.41785\n",
      "74/74 [==============================] - 35s 480ms/step - loss: 0.4069 - accuracy: 0.8607 - val_loss: 0.4466 - val_accuracy: 0.8494\n",
      "Epoch 46/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4088 - accuracy: 0.8597\n",
      "Epoch 00046: val_loss did not improve from 0.41785\n",
      "74/74 [==============================] - 35s 473ms/step - loss: 0.4088 - accuracy: 0.8597 - val_loss: 0.4787 - val_accuracy: 0.8363\n",
      "Epoch 47/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4053 - accuracy: 0.8608\n",
      "Epoch 00047: val_loss did not improve from 0.41785\n",
      "74/74 [==============================] - 35s 478ms/step - loss: 0.4053 - accuracy: 0.8608 - val_loss: 0.4212 - val_accuracy: 0.8553\n",
      "Epoch 48/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4053 - accuracy: 0.8605\n",
      "Epoch 00048: val_loss did not improve from 0.41785\n",
      "74/74 [==============================] - 35s 476ms/step - loss: 0.4053 - accuracy: 0.8605 - val_loss: 0.5970 - val_accuracy: 0.8035\n",
      "Epoch 49/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4230 - accuracy: 0.8536\n",
      "Epoch 00049: val_loss did not improve from 0.41785\n",
      "74/74 [==============================] - 34s 461ms/step - loss: 0.4230 - accuracy: 0.8536 - val_loss: 0.5070 - val_accuracy: 0.8276\n",
      "Epoch 50/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4065 - accuracy: 0.8598\n",
      "Epoch 00050: val_loss did not improve from 0.41785\n",
      "74/74 [==============================] - 34s 460ms/step - loss: 0.4065 - accuracy: 0.8598 - val_loss: 0.5220 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc5fb97fa30>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep = 50\n",
    "model.fit(train_dt,y_train_,validation_data=(cv_dt,y_cv_),epochs=ep,batch_size=batch,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
